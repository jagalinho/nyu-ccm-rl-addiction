{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d5aad5a-a6f3-4496-a4ce-c7c8df651e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=150, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35755424-1b5a-448d-89a8-98481b9e1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddictionWorld():\n",
    "    def __init__(self, max_time, n_trials, ETA=1, GAMMA=1, rewards=[], substances=[], verbose=False):\n",
    "\n",
    "        self.max_time = max_time\n",
    "        self.n_trials = n_trials\n",
    "        self.reward = np.zeros((self.n_trials, self.max_time))\n",
    "        self.addiction = np.zeros((self.n_trials, self.max_time))\n",
    "        self.value = np.zeros((self.n_trials, self.max_time))\n",
    "        self.prediction_error = np.zeros((self.n_trials, self.max_time))\n",
    "        self.learning_rate = ETA\n",
    "        self.discount_rate = GAMMA\n",
    "\n",
    "        for args in rewards:\n",
    "            self.add_reward(*args)\n",
    "            \n",
    "        for args in substances:\n",
    "            self.add_substance(*args)\n",
    "\n",
    "    def add_reward(self, reward, time, trials=None, verbose=False):\n",
    "        if time >= self.max_time:\n",
    "            raise ValueError(f\"Tried to add reward on time {time} when max_time is {self.max_time}\")\n",
    "        \n",
    "        if trials is None:\n",
    "            trial_range = (0, self.n_trials)\n",
    "        else:\n",
    "            if trials[1] >= self.n_trials:\n",
    "                raise ValueError(f\"Tried to add rewards for trials {trials[0]}-{trials[1]} when there are only {self.n_trials}\")\n",
    "            trial_range = trials\n",
    "        if verbose:\n",
    "            print(f\"Adding reward of {reward} on time {time} for trials {trial_range}\")\n",
    "        self.reward[trial_range[0]:trial_range[1], time] = reward\n",
    "        print('Reward added')\n",
    "        if verbose:\n",
    "            print(self.reward)\n",
    "            \n",
    "    \n",
    "    def add_substance(self, reward, addiction, time, trials=None, verbose=False):\n",
    "        self.add_reward(reward, time, trials, verbose)\n",
    "        \n",
    "        if trials is None:\n",
    "            trial_range = (0, self.n_trials)\n",
    "        else:\n",
    "            trial_range = trials\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"Adding addiction of {addiction} on time {time} for trials {trial_range}\")\n",
    "        self.addiction[trial_range[0]:trial_range[1], time] = addiction  \n",
    "        print('Substance added')\n",
    "        if verbose:\n",
    "            print(self.addiction)\n",
    "        \n",
    "\n",
    "    def clear_reward(self, time, trials, verbose=False):\n",
    "        if time >= self.max_time:\n",
    "            raise ValueError(f\"Tried to clear rewards on time {time} when max_time is {self.max_time}\")\n",
    "\n",
    "        if trials[1] >= self.n_trials:\n",
    "            raise ValueError(f\"Tried to clear rewards for trials {trials[0]}-{trials[1]} when there are only {self.n_trials}\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Clearing rewards on time {time} for trials {trials[0]}-{trials[1]}\")\n",
    "        self.reward[trial_range[0]:trial_range[1], time] = 0\n",
    "        print('Reward cleared')\n",
    "        if verbose:\n",
    "            print(self.reward)\n",
    "\n",
    "        \n",
    "    def run_TD(self):\n",
    "        \"\"\"\n",
    "        Function which simulates trials, updating values and recording prediction error\n",
    "        \n",
    "        ETA -> Learning rate\n",
    "        GAMMA -> Discount rate for future reward\n",
    "        \"\"\"\n",
    "\n",
    "        for trial in range(self.n_trials):\n",
    "            for t in range(self.max_time-1):\n",
    "                expected_value = self.value[trial][t]\n",
    "                actual_value = self.reward[trial][t] + self.discount_rate * (self.value[trial][t+1])\n",
    "                prediction_error = np.max([(actual_value - expected_value + self.addiction[trial][t]), \n",
    "                                           self.addiction[trial][t]])\n",
    "                self.prediction_error[trial][t] = prediction_error\n",
    "                if trial < (self.n_trials - 1):\n",
    "                    self.value[trial+1][t] = expected_value + (self.learning_rate * prediction_error)\n",
    "        print('TD learning complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c9dd7cc-d866-44c8-9ef5-1092468d2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward added\n",
      "Reward added\n",
      "Substance added\n",
      "TD learning complete\n",
      "[[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    5.    0.    0.    0.    2.75  0.  ]\n",
      " [ 0.    0.    0.    1.25  7.5   0.    0.    0.69  4.12  0.  ]\n",
      " [ 0.    0.    0.31  2.5   8.75  0.    0.17  1.38  4.81  0.  ]\n",
      " [ 0.    0.08  0.78  3.44  9.38  0.04  0.43  1.89  5.16  0.  ]\n",
      " [ 0.02  0.23  1.25  4.06  9.7   0.13  0.69  2.23  5.41  0.  ]\n",
      " [ 0.07  0.43  1.64  4.46  9.88  0.24  0.9   2.47  5.66  0.  ]\n",
      " [ 0.14  0.62  1.93  4.7  10.    0.34  1.07  2.65  5.91  0.  ]\n",
      " [ 0.23  0.8   2.14  4.85 10.09  0.44  1.2   2.8   6.16  0.  ]\n",
      " [ 0.31  0.93  2.28  4.95 10.15  0.52  1.3   2.94  6.41  0.  ]\n",
      " [ 0.39  1.04  2.38  5.01 10.21  0.58  1.38  3.07  6.66  0.  ]\n",
      " [ 0.45  1.11  2.44  5.06 10.25  0.64  1.46  3.2   6.91  0.  ]\n",
      " [ 0.51  1.17  2.49  5.09 10.28  0.68  1.53  3.33  7.16  0.  ]\n",
      " [ 0.54  1.2   2.52  5.12 10.31  0.72  1.6   3.45  7.41  0.  ]\n",
      " [ 0.57  1.23  2.54  5.14 10.34  0.76  1.66  3.58  7.66  0.  ]\n",
      " [ 0.59  1.25  2.55  5.15 10.36  0.8   1.73  3.7   7.91  0.  ]\n",
      " [ 0.61  1.26  2.56  5.17 10.38  0.83  1.79  3.83  8.16  0.  ]\n",
      " [ 0.62  1.27  2.57  5.18 10.4   0.86  1.85  3.95  8.41  0.  ]\n",
      " [ 0.63  1.28  2.58  5.19 10.41  0.89  1.91  4.08  8.66  0.  ]\n",
      " [ 0.63  1.29  2.59  5.2  10.43  0.93  1.98  4.2   8.91  0.  ]\n",
      " [ 0.64  1.29  2.59  5.21 10.45  0.96  2.04  4.33  9.16  0.  ]\n",
      " [ 0.64  1.29  2.6   5.21 10.46  0.99  2.1   4.45  9.41  0.  ]\n",
      " [ 0.64  1.3   2.6   5.22 10.48  1.02  2.16  4.58  9.66  0.  ]\n",
      " [ 0.65  1.3   2.61  5.23 10.49  1.05  2.23  4.7   9.91  0.  ]\n",
      " [ 0.65  1.3   2.61  5.24 10.51  1.08  2.29  4.83 10.16  0.  ]\n",
      " [ 0.65  1.3   2.62  5.25 10.53  1.11  2.35  4.95 10.41  0.  ]\n",
      " [ 0.65  1.31  2.62  5.25 10.54  1.14  2.41  5.08 10.66  0.  ]\n",
      " [ 0.65  1.31  2.62  5.26 10.56  1.18  2.48  5.2  10.91  0.  ]\n",
      " [ 0.65  1.31  2.63  5.27 10.57  1.21  2.54  5.33 11.16  0.  ]\n",
      " [ 0.65  1.31  2.63  5.28 10.59  1.24  2.6   5.45 11.41  0.  ]\n",
      " [ 0.65  1.31  2.64  5.29 10.6   1.27  2.66  5.58 11.66  0.  ]\n",
      " [ 0.66  1.32  2.64  5.29 10.62  1.3   2.73  5.7  11.91  0.  ]\n",
      " [ 0.66  1.32  2.64  5.3  10.63  1.33  2.79  5.83 12.16  0.  ]\n",
      " [ 0.66  1.32  2.65  5.31 10.65  1.36  2.85  5.95 12.41  0.  ]\n",
      " [ 0.66  1.32  2.65  5.32 10.67  1.39  2.91  6.08 12.66  0.  ]\n",
      " [ 0.66  1.32  2.65  5.33 10.68  1.43  2.98  6.2  12.91  0.  ]\n",
      " [ 0.66  1.33  2.66  5.33 10.7   1.46  3.04  6.33 13.16  0.  ]\n",
      " [ 0.66  1.33  2.66  5.34 10.71  1.49  3.1   6.45 13.41  0.  ]\n",
      " [ 0.66  1.33  2.67  5.35 10.73  1.52  3.16  6.58 13.66  0.  ]\n",
      " [ 0.66  1.33  2.67  5.36 10.74  1.55  3.23  6.7  13.91  0.  ]\n",
      " [ 0.66  1.33  2.67  5.36 10.76  1.58  3.29  6.83 14.16  0.  ]\n",
      " [ 0.67  1.34  2.68  5.37 10.78  1.61  3.35  6.95 14.41  0.  ]\n",
      " [ 0.67  1.34  2.68  5.38 10.79  1.64  3.41  7.08 14.66  0.  ]\n",
      " [ 0.67  1.34  2.69  5.39 10.81  1.68  3.48  7.2  14.91  0.  ]\n",
      " [ 0.67  1.34  2.69  5.4  10.82  1.71  3.54  7.33 15.16  0.  ]\n",
      " [ 0.67  1.34  2.69  5.4  10.84  1.74  3.6   7.45 15.41  0.  ]\n",
      " [ 0.67  1.34  2.7   5.41 10.85  1.77  3.66  7.58 15.66  0.  ]\n",
      " [ 0.67  1.35  2.7   5.42 10.87  1.8   3.73  7.7  15.91  0.  ]\n",
      " [ 0.67  1.35  2.71  5.43 10.88  1.83  3.79  7.83 16.16  0.  ]\n",
      " [ 0.67  1.35  2.71  5.43 10.9   1.86  3.85  7.95 16.41  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "aw = AddictionWorld(max_time=10, n_trials=50, ETA=0.5, GAMMA=.5, rewards=[(10, 4)], substances=[(5, 0.5, 8)])\n",
    "\n",
    "aw.run_TD()\n",
    "print(aw.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c6a9a35-d941-4d58-b911-fb50161d8fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.    0.   10.    0.    0.    0.    5.5   0.  ]\n",
      " [ 0.    0.    0.    2.5   5.    0.    0.    1.38  2.75  0.  ]\n",
      " [ 0.    0.    0.62  2.5   2.5   0.    0.34  1.38  1.38  0.  ]\n",
      " [ 0.    0.16  0.94  1.88  1.25  0.09  0.52  1.03  0.69  0.  ]\n",
      " [ 0.04  0.31  0.94  1.25  0.65  0.17  0.52  0.69  0.5   0.  ]\n",
      " [ 0.1   0.39  0.78  0.79  0.37  0.21  0.43  0.47  0.5   0.  ]\n",
      " [ 0.15  0.39  0.59  0.48  0.24  0.21  0.33  0.36  0.5   0.  ]\n",
      " [ 0.17  0.34  0.41  0.3   0.17  0.19  0.26  0.3   0.5   0.  ]\n",
      " [ 0.17  0.27  0.28  0.19  0.13  0.16  0.2   0.28  0.5   0.  ]\n",
      " [ 0.15  0.21  0.19  0.13  0.11  0.13  0.17  0.26  0.5   0.  ]\n",
      " [ 0.13  0.15  0.13  0.09  0.09  0.11  0.15  0.26  0.5   0.  ]\n",
      " [ 0.1   0.11  0.09  0.07  0.07  0.09  0.14  0.25  0.5   0.  ]\n",
      " [ 0.08  0.08  0.06  0.05  0.06  0.08  0.13  0.25  0.5   0.  ]\n",
      " [ 0.06  0.05  0.04  0.04  0.05  0.07  0.13  0.25  0.5   0.  ]\n",
      " [ 0.04  0.04  0.03  0.03  0.04  0.07  0.13  0.25  0.5   0.  ]\n",
      " [ 0.03  0.03  0.02  0.03  0.04  0.07  0.13  0.25  0.5   0.  ]\n",
      " [ 0.02  0.02  0.02  0.02  0.04  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.02  0.01  0.02  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.01  0.01  0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.01  0.01  0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.01  0.01  0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.01  0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.01  0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]\n",
      " [ 0.    0.    0.01  0.02  0.03  0.06  0.13  0.25  0.5   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(aw.prediction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd5aef-ecd7-4a7d-88b5-fa2974d284a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
